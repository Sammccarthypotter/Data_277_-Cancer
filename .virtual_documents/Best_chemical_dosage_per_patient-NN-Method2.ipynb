


import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import time as time
import torch
import torch.nn as nn
import torch.nn.functional as F
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


valid_IC50s = pd.read_csv("valid_IC50s_within_range.csv")
merged_df = pd.read_csv("final_merged.csv")
lucas_df = pd.read_csv("final_mapping.csv")
cell_lines_df = pd.read_csv("data/HarvardCellLines.csv")


valid_IC50s


cell_lines_df


lucas_df


valid_IC50s.drop(columns = ['Unnamed: 0', 'N Points'], inplace = True)


cell_lines_df.columns


columns = ["HMS LINCS ID", "Name", "T Stage"]
cell_lines_df = cell_lines_df[columns]





merged_df["Race"].value_counts()


# # TEMPORARY IMPUTATION OF RACE BASED OFF PROPORTIONS OF EXISTING RACES.
# # WILL USE AUSTIN'S IMPUTED RACE ANALYSIS LATER.

# # Get value counts as probabilities
# race_dist = merged_df['Race'].value_counts(normalize=True)

# # Get the indices where race is missing
# missing_indices = lucas_df['Cell_Line_Race'].isna()

# # Sample values based on observed distribution
# imputed_values = np.random.choice(race_dist.index, size=missing_indices.sum(), p=race_dist.values)

# # Assign the sampled values to the missing positions
# lucas_df.loc[missing_indices, 'Cell_Line_Race'] = imputed_values



# TEMPORARY IMPUTATION OF RACE BASED OFF PROPORTIONS OF EXISTING RACES.
# WILL USE AUSTIN'S IMPUTED RACE ANALYSIS LATER.

# Get value counts as probabilities
race_dist = merged_df['Race'].value_counts(normalize=True)

# Get the indices where race is missing
missing_indices = merged_df['Race'].isna()

# Sample values based on observed distribution
imputed_values = np.random.choice(race_dist.index, size=missing_indices.sum(), p=race_dist.values)

# Assign the sampled values to the missing positions
merged_df.loc[missing_indices, 'Race'] = imputed_values


def T_stage_by_size(size):
    if size == 0:
        return 0
    if size > 0 and size <= 20:
        return 1
    if size > 20 and size <= 50:
        return 2
    if size > 50:
        return 3


merged_df['T_stage_by_size'] = merged_df.apply(lambda row: row['T Stage'] if pd.notnull(row['T Stage']) else T_stage_by_size(row['Tumor Size']), axis=1)


merged_df['T_stage_by_size'].isna().sum()


columns = ['Age', 'Race', 'T_stage_by_size']
patients_df = merged_df[columns]


patients_df


patients_df.isna().sum()


valid_IC50s





def get_biased_cell_lines(patient_row, cell_line_df, n=3):
    # Filter for matching T_stage
    filtered = cell_line_df[cell_line_df["T Stage"] == patient_row["T_stage_by_size"]]

    # If fewer than n matches, fall back to all cell lines
    if len(filtered) < n:
        filtered = cell_line_df

    return np.random.choice(filtered["HMS LINCS ID"], size=n, replace=False).tolist()


patients_df["T_stage_by_size"].apply(type).value_counts()


cell_lines_df["T Stage"].apply(type).value_counts()


# Add a list of 3 biased cell lines per patient
patients_df["cell_lines"] = patients_df.apply(lambda row: get_biased_cell_lines(row, cell_lines_df), axis=1)



patients_df


# Explode so each row = 1 (patient, cell_line)
patients_df = patients_df.explode("cell_lines").reset_index(drop=True)


cell_lines_df_dict = cell_lines_df.set_index("HMS LINCS ID").to_dict()["Name"]
display(cell_lines_df_dict)

def cell_name_map(row, dictionary):
    return dictionary[row]


patients_df["Cell Name"] = patients_df["cell_lines"].apply(cell_name_map, dictionary = cell_lines_df_dict)


patients_df


# ASK TEAM TO HELP IMPUTE MISSING T-STAGE OR DROP THEIR ROWS 
# MAYBE ASK AUSTIN FOR SIMILAR WORKFLOW USED FOR RACE BUT FOR T-STAGE 
patients_df.dropna(inplace=True)
patients_df.isna().sum()





drugs_df = pd.read_csv("Descriptors_Small_Molecules.csv")
drugs_df = drugs_df[['Name', 'Molecular Mass', 'LogP', 'NumHDonors', 'NumHAcceptors', 'TPSA']]
drugs_df.rename(columns={'Name': 'Small Molecule Name'}, inplace=True)
drugs_df.head()


valid_IC50s.columns


valid_IC50s = pd.merge(valid_IC50s, drugs_df, on='Small Molecule Name', how='left')


valid_IC50s.head(3)


patients_df.head(3)


patient_drug_df = pd.merge(patients_df, valid_IC50s, on='Cell Name', how='left')


patient_drug_df.drop(columns = "cell_lines", inplace=True)


patient_drug_df.to_csv("patient_drug_information_aka_final_final_final.csv")


patient_drug_df


race_dict = {0:'N/A', 1:"white", 2:"black", 3:"asian", 4:"native", 5:"hispanic", 6:"multi", 7:"hawa", 8:"amer indian"}

def race_map(row, dictionary):
    return dictionary[row]


patient_drug_df["Race"] = patient_drug_df["Race"].apply(race_map, dictionary = race_dict)


patient_drug_df





patient_drug_df.drop(columns="Cell Name", inplace=True)


patient_drug_df





categorical_cols = ['Race', 'T_stage_by_size', 'Small Molecule Name']
patient_drug_df[categorical_cols] = patient_drug_df[categorical_cols].astype('category')


patient_drug_df_encoded = pd.get_dummies(patient_drug_df, columns=categorical_cols, drop_first=True)
print(patient_drug_df_encoded.dtypes)


bool_cols = patient_drug_df_encoded.select_dtypes(include='bool').columns
patient_drug_df_encoded[bool_cols] = patient_drug_df_encoded[bool_cols].astype(int)


patient_drug_df_encoded.head(3)





from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


# Separate features (X) and target (y)
X = patient_drug_df_encoded.drop(columns=['EC50 (uM)'])  # Drop EC50 and non-features
y = patient_drug_df_encoded['EC50 (uM)']  # EC50 is the target

# Standardize numerical features
scaler = StandardScaler()
X[['Age', 'Molecular Mass', 'LogP', 'NumHDonors', 'NumHAcceptors', 'TPSA']] = scaler.fit_transform(X[['Age', 'Molecular Mass', 'LogP', 'NumHDonors', 'NumHAcceptors', 'TPSA']]) 


X


# Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# FEED FORWARD NEURAL NETWORK - 2 LAYERS

class DrugEncoder(nn.Module):
    def __init__(self, input_dim=5):  # 5 molecular descriptors
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 32)
        )

    def forward(self, x):
        return self.encoder(x.float())

# SIMGPLE FEED FORWARD NEURAL NETWORK 
class PatientEncoder(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 32)
        )

    def forward(self, x):
        return self.encoder(x.float())

# REGRESSION PREDICTION WITH SIMPLE FEED FORWARD NEURAL NETWORK

class DrugResponsePredictor(nn.Module):
    def __init__(self, drug_input_dim, patient_input_dim):
        super().__init__()
        self.drug_encoder = DrugEncoder(drug_input_dim)
        self.patient_encoder = PatientEncoder(patient_input_dim)
        self.fc = nn.Sequential(
            nn.Linear(32 + 32, 32),
            nn.ReLU(),
            nn.Linear(32, 1)  # IC50 prediction
        )

    def forward(self, drug_feat, patient_feat):
        drug_vec = self.drug_encoder(drug_feat)
        patient_vec = self.patient_encoder(patient_feat)
        combined = torch.cat([drug_vec, patient_vec], dim=1)
        return self.fc(combined).squeeze(-1)



# Data
# Select drug descriptor columns
drug_feature_cols = ['Molecular Mass', 'LogP', 'NumHDonors', 'NumHAcceptors', 'TPSA']
drug_features = X_train[drug_feature_cols].to_numpy()  # (n_samples, 5)

# Drop drug features to get patient features
patient_features = X_train.drop(columns=drug_feature_cols).to_numpy()

# Convert to tensors
drug_tensor = torch.tensor(drug_features).float()
patient_tensor = torch.tensor(patient_features).float()
ic50_tensor = torch.tensor(y_train.to_numpy()).float()

model = DrugResponsePredictor(drug_input_dim=5, patient_input_dim=patient_tensor.shape[1])
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
loss_fn = nn.MSELoss()


# Training loop
model.train()
start_time = time.time()

for epoch in range(300):  # increase epochs for real training
    optimizer.zero_grad()
    preds = model(drug_tensor, patient_tensor)
    loss = loss_fn(preds, ic50_tensor)
    loss.backward()
    optimizer.step()
    end_time = time.time()
    elapsed = end_time - start_time
    print(f"Epoch {epoch} | Loss: {loss.item():.4f}")
    print(f"Time elapsed: {elapsed:.2f} seconds")



def evaluate_model(model, drug_features, patient_features, true_ic50s):
    # Convert to numpy 
    if hasattr(drug_features, 'to_numpy'):
        drug_features = drug_features.to_numpy()
    if hasattr(patient_features, 'to_numpy'):
        patient_features = patient_features.to_numpy()
    if hasattr(true_ic50s, 'to_numpy'):
        true_ic50s = true_ic50s.to_numpy()

    # Convert to tensors
    drug_tensor = torch.tensor(drug_features).float()
    patient_tensor = torch.tensor(patient_features).float()
    true_ic50_tensor = torch.tensor(true_ic50s).float()

    # Inference
    model.eval()
    with torch.no_grad():
        preds = model(drug_tensor, patient_tensor).cpu().numpy()
        targets = true_ic50_tensor.cpu().numpy()

    # Metrics
    mse = mean_squared_error(targets, preds)
    mae = mean_absolute_error(targets, preds)
    r2 = r2_score(targets, preds)

    return mse, mae, r2



drug_features_test = X_test[['Molecular Mass', 'LogP', 'NumHDonors', 'NumHAcceptors', 'TPSA']]
patient_features_test = X_test.drop(columns=drug_features_test.columns)

metrics = evaluate_model(model, drug_features_test, patient_features_test, y_test)

print(f"MSE: {metrics[0]:.4f}")
print(f"MAE: {metrics[1]:.4f}")
print(f"RÂ²: {metrics[2]:.4f}")



def plot_pred_vs_true(true, preds):
    plt.figure(figsize=(8, 6))
    plt.scatter(true, preds, alpha=0.6, label='Predictions')
    
    plt.plot([true.min(), true.max()], [true.min(), true.max()], 'r--', label='Ideal')

    slope, intercept = np.polyfit(true, preds, 1)
    plt.plot(true, slope * true + intercept, 'g-', label='Best Fit Line')

    plt.xlabel("True IC50")
    plt.ylabel("Predicted IC50")
    plt.title("True vs. Predicted IC50 values\nModel trained with 300 epochs\nExcluding Cell Line information")
    plt.legend()
    plt.tight_layout()
    plt.show()


with torch.no_grad():
    preds = model(torch.tensor(drug_features_test.values).float(),
                  torch.tensor(patient_features_test.values).float()).cpu().numpy()
plot_pred_vs_true(y_test.to_numpy(), preds)



