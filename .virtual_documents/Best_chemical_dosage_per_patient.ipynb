





import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

valid_IC50s = pd.read_csv("valid_IC50s_within_range.csv")
merged_df = pd.read_csv("final_merged.csv")
lucas_df = pd.read_csv("final_mapping.csv")
cell_lines_df = pd.read_csv("data/HarvardCellLines.csv")


valid_IC50s.drop(columns = ['Unnamed: 0', 'N Points'], inplace = True)


cell_lines_df.columns


columns = ["HMS LINCS ID", "Name"]
cell_lines_df = cell_lines_df[columns]


display(lucas_df.shape)
lucas_df["Matched Cell Line ID"].value_counts()


cell_lines_df_dict = cell_lines_df.set_index("HMS LINCS ID").to_dict()["Name"]
cell_lines_df_dict


def cell_name_map(row, dictionary):
    return dictionary[row["Cell_Line"]]


merged_df["Race"].value_counts()


lucas_df["Cell_Line_Race"] = np.nan # TEMPORARY CELL 


# TEMPORARY IMPUTATION OF RACE BASED OFF PROPORTIONS OF EXISTING RACES.
# WILL USE AUSTIN'S IMPUTED RACE ANALYSIS LATER.

# Get value counts as probabilities
race_dist = merged_df['Race'].value_counts(normalize=True)

# Get the indices where race is missing
missing_indices = lucas_df['Cell_Line_Race'].isna()

# Sample values based on observed distribution
imputed_values = np.random.choice(race_dist.index, size=missing_indices.sum(), p=race_dist.values)

# Assign the sampled values to the missing positions
lucas_df.loc[missing_indices, 'Cell_Line_Race'] = imputed_values



# TEMPORARY IMPUTATION OF RACE BASED OFF PROPORTIONS OF EXISTING RACES.
# WILL USE AUSTIN'S IMPUTED RACE ANALYSIS LATER.

# Get value counts as probabilities
race_dist = merged_df['Race'].value_counts(normalize=True)

# Get the indices where race is missing
missing_indices = merged_df['Race'].isna()

# Sample values based on observed distribution
imputed_values = np.random.choice(race_dist.index, size=missing_indices.sum(), p=race_dist.values)

# Assign the sampled values to the missing positions
merged_df.loc[missing_indices, 'Race'] = imputed_values


lucas_df["Cell_Line_Race"].value_counts()


merged_df[["Race"]]


def T_stage_by_size(size):
    if size == 0:
        return 0
    if size > 0 and size <= 20:
        return 1
    if size > 20 and size <= 50:
        return 2
    if size > 50:
        return 3


merged_df['T_stage_by_size'] = merged_df.apply(lambda row: row['T Stage'] if pd.notnull(row['T Stage']) else T_stage_by_size(row['Tumor Size']), axis=1)


merged_df['T_stage_by_size'].isna().sum()


columns = ['Patient ID', 'Age', 'Race', 'T_stage_by_size']
patients_df = merged_df[columns]


patients_df


patients_df.isna().sum()


valid_IC50s


# ASK LUCAS FOR THIS DATA
patients_df = patients_df.copy()

# Assign a random integer between 1 and 34 for each row
patients_df['cell_line'] = np.random.randint(1, 36, size=len(patients_df))


patients_df





# ASK TEAM TO HELP IMPUTE MISSING T-STAGE OR DROP THEIR ROWS 
# MAYBE ASK AUSTIN FOR SIMILAR WORKFLOW USED FOR RACE BUT FOR T-STAGE 
patients_df.isna().sum()





valid_IC50s


# Get unique cell line names
unique_cell_lines = valid_IC50s['Cell Name'].unique()

# Create a mapping from cell line name to number (1 to 34)
cell_line_map = {name: i+1 for i, name in enumerate(unique_cell_lines)}

# Preview the result
print(cell_line_map)

valid_IC50s['Cell_Name_Mapped'] = valid_IC50s['Cell Name'].map(cell_line_map)


valid_IC50s


# One-hot encode 'Small Molecule Name'
one_hot_encoded = pd.get_dummies(valid_IC50s['Small Molecule Name'], dtype='int')

# Concatenate the one-hot encoded columns back to the original DataFrame
valid_IC50s_encoded = pd.concat([valid_IC50s, one_hot_encoded], axis=1)


valid_IC50s_encoded


patients_df


# Make sure both dataframes have a matching cell line column
# Map Cell Name (string) to cell_line_id (integer) in the drug data
valid_IC50s_encoded['cell_line_id'] = valid_IC50s_encoded['Cell Name'].map(cell_line_map)

# Merge patients with drug data on cell_line == cell_line_id
# This will replicate each patient row once per matching drug for their cell line
patient_drug_df = patients_df.merge(
    valid_IC50s_encoded,
    left_on='cell_line',
    right_on='cell_line_id',
    how='inner' )



patient_drug_df.drop(columns="cell_line", inplace=True)


race_dict = {0:'N/A', 1:"white", 2:"black", 3:"asian", 4:"native", 5:"hispanic", 6:"multi", 7:"hawa", 8:"amer indian"}


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn import tree


# Separate features (X) and target (y)
X = patient_drug_df.drop(columns=['Patient ID', 'EC50 (uM)', 'Small Molecule Name', 'Cell Name', 'cell_line_id'])  # Drop EC50 and non-features
y = patient_drug_df['EC50 (uM)']  # EC50 is the target

# Standardize numerical features
scaler = StandardScaler()
X[['Age']] = scaler.fit_transform(X[['Age']]) 

# Need to one-hot encode categorical variables: Race, Drug name, Cell line name
X = pd.get_dummies(X, columns=['Cell_Name_Mapped', 'Race', 'T_stage_by_size'],dtype='int', drop_first=False)


X_train


# Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the model
model = RandomForestRegressor(n_estimators=10, random_state=42, n_jobs = -1, verbose = 2)

# Train the model
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error (MSE): {mse}')


r2 = r2_score(y_test, y_pred)
print(f'R² Score: {r2}')


from sklearn import tree
plt.figure(figsize=(10, 10)) 
tree.plot_tree(
    model.estimators_[0], 
    filled=True, 
    feature_names=X.columns, 
    max_depth=4,
    fontsize = 10)
plt.tight_layout()
plt.show()



# Get the feature importances from the trained model
importances = model.feature_importances_


X_train.to_csv("X_train.csv")


features = X[1:45].columns  # Column names from the features
importance_df = pd.DataFrame({
    'Feature': features,
    'Importance': importances})

# Sort by importance (descending order)
importance_df = importance_df.sort_values(by='Importance', ascending=False)

# Display the importance of each feature
print(importance_df)


# Plot feature importance
plt.figure(figsize=(10, 15))
plt.barh(importance_df['Feature'], importance_df['Importance'])
plt.xlabel('Importance')
plt.title('Feature Importance')
plt.gca().invert_yaxis()  # To display the most important feature at the top
plt.show()








# Create a template with all zero values
new_patient = (pd.DataFrame(X.iloc[3,:])).T


new_patient


new_patient["T_stage_by_size_2.0"] = 0
new_patient["T_stage_by_size_4.0"] = 1
new_patient["Age"] = 26


new_patient


# Standardize Age using the same scaler used during training
new_patient[['Age']] = scaler.transform(new_patient[['Age']])


# List of non-drug columns and non-one-hot-encoded
non_drug_columns = ['Age', 'Race', 'cell_line', 'Patient ID', 'T_stage_by_size', 'Survival Months', 'Cell Name', 'Small Molecule Name', 'EC50 (uM)', 'Cell_Name_Mapped']

drug_columns = [col for col in X.columns if col not in non_drug_columns]


# Get drug columns by excluding non-drug columns
drug_columns = [col for col in X.columns if col not in non_drug_columns]
results = []

# Loop through each drug and make a prediction
for drug in drug_columns:
    temp_input = new_patient.copy()
    temp_input[drug] = 1
    try:
        ec50 = model.predict(temp_input)[0]
        results.append((drug, ec50))
    except Exception as e:
        print(f"Error predicting for {drug}: {e}")

# Sort drugs by predicted EC50 (lower is better)
results = sorted(results, key=lambda x: x[1])

# Display top 5 recommended drugs
Top_5 = []
for drug, ec50 in results[:5]:
    print(f'{drug}: predicted EC50 = {ec50:.4f} µM')
    Top_5.append(drug)



from rdkit import Chem
from rdkit.Chem import Draw
from rdkit.Chem import AllChem
from rdkit.Chem import DataStructs
from IPython.display import display, HTML


SmallMolecules = pd.read_csv("data/HarvardSmallMolecules.csv")


columns = ['Name', 'Molecular Mass', 'SMILES']
SmallMolecules = SmallMolecules[columns]


from rdkit import Chem
from rdkit.Chem import Draw

# Prepare molecules and names
mols = [Chem.MolFromSmiles(smiles) for smiles in SmallMolecules["SMILES"]]
names = SmallMolecules["Name"].tolist()

# Create image with names as legends
img = Draw.MolsToGridImage(
    mols,
    legends=names,
    molsPerRow=5,  # Adjust for layout, e.g. 5 columns x 7 rows
    subImgSize=(200,200)  # Size of each molecule image
)

# Show the image (in Jupyter)
from IPython.display import display
display(img)



SmallMolecules["Fingerprint"] = pd.Series(mols).apply(lambda mol: AllChem.GetMorganFingerprintAsBitVect(mol, radius=10, nBits=2048))


SmallMolecules["Mol"] = mols
SmallMolecules


# Select top 5 drugs recommended for test patient
subset = SmallMolecules[SmallMolecules["Name"].isin(Top_5)]
subset





mol_list = subset["Mol"].tolist()
legends = subset["Name"].tolist()

img = Draw.MolsToGridImage(mol_list, molsPerRow=5, legends=legends, subImgSize=(200,200))
display(img)



from rdkit.DataStructs import TanimotoSimilarity

fps = SmallMolecules["Fingerprint"].tolist()
names = SmallMolecules["Name"].tolist()
n = len(fps)

# similarity matrix
sim_matrix = np.zeros((n, n))
for i in range(n):
    for j in range(n):
        sim_matrix[i, j] = TanimotoSimilarity(fps[i], fps[j])

sim_df = pd.DataFrame(sim_matrix, index=names, columns=names)


plt.figure(figsize=(20,10))
sns.heatmap(sim_df, annot=True, cmap="Blues", fmt=".2f")
plt.title("Tanimoto Similarity Between 34 Small Molecules")
plt.show()


fps = subset["Fingerprint"].tolist()
names = subset["Name"].tolist()
n = len(fps)

# similarity matrix
sim_matrix = np.zeros((n, n))
for i in range(n):
    for j in range(n):
        sim_matrix[i, j] = TanimotoSimilarity(fps[i], fps[j])

# Convert to DataFrame for clarity
subset_sim_df = pd.DataFrame(sim_matrix, index=names, columns=names)

plt.figure(figsize=(8,6))
sns.heatmap(subset_sim_df, annot=True, cmap="Blues", fmt=".2f")
plt.title("Tanimoto Similarity Between Top 5 Selected Drugs for Test patient")
plt.show()


from rdkit.Chem import Crippen

# Calculate logP
SmallMolecules["logP"] = SmallMolecules["Mol"].apply(Crippen.MolLogP)



SmallMolecules


plt.figure(figsize=(10, 5))
bars = plt.scatter(SmallMolecules["Molecular Mass"], SmallMolecules["logP"], color='skyblue')

# Add horizontal line at 0
plt.axhline(0, color='gray', linewidth=0.8)

# Labels and title
plt.ylabel("logP")
plt.title("logP Values of Compounds", pad=20)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()

plt.show()


plt.figure(figsize=(10, 5))
bars = plt.bar(SmallMolecules["Name"], SmallMolecules["logP"], color='skyblue')

# Add horizontal line at 0
plt.axhline(0, color='gray', linewidth=0.8)

# Labels and title
plt.ylabel("logP")
plt.title("logP Values of Compounds", pad=20)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()

plt.show()




